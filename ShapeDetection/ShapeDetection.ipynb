{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShapeDetection\n",
    "\n",
    "Based on __[jrieke / shape-detection](https://github.com/jrieke/shape-detection/blob/master/single-rectangle.ipynb)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_size = 8\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "\n",
    "def make_image(img):\n",
    "    if np.random.rand(1) <= 0.2:\n",
    "        exists = 0.0\n",
    "        bbox = [0.0, 0.0, 0.0, 0.0]\n",
    "    else:\n",
    "        exists = 1.0\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "        x = np.random.randint(0, img_size - w)\n",
    "        y = np.random.randint(0, img_size - h)\n",
    "        img[x:x+w, y:y+h] = 1.  # set rectangle to 1\n",
    "        bbox = [x, y, w, h]\n",
    "    return (exists, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images with random rectangles and bounding boxes. \n",
    "num_imgs = 50000\n",
    "\n",
    "imgs = np.zeros((num_imgs, img_size, img_size))  # set background to 0\n",
    "exists = np.zeros((num_imgs, 1))\n",
    "bboxes = np.zeros((num_imgs, 4))   # x, y, w, h\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    exists[i_img], bboxes[i_img] = make_image(imgs[i_img])\n",
    "    \n",
    "# print(imgs[0])\n",
    "# print(exists[0])\n",
    "# print(bboxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to match the input shape of the neural network.\n",
    "X = imgs.reshape(num_imgs, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data):\n",
    "    i = int(0.8 * num_imgs)\n",
    "    train_data = data[ :i ]\n",
    "    test_data = data[ i: ]\n",
    "    return (train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test.\n",
    "train_X, test_X = split_train_test(X)\n",
    "train_y_exists, test_y_exists = split_train_test(exists)\n",
    "train_y_bboxes, test_y_bboxes = split_train_test(bboxes)\n",
    "train_imgs, test_imgs = split_train_test(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import binary_crossentropy, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "y_true_exists = None\n",
    "    \n",
    "def exists_loss(y_true, y_pred):\n",
    "    global y_true_exists\n",
    "    y_true_exists = tf.transpose(y_true[ : , 0])\n",
    "    return binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "def bboxes_loss(y_true, y_pred):\n",
    "    global y_true_exists\n",
    "    return y_true_exists * mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 つ目の Dense\n",
    "  - 入力が 64\n",
    "  - ニューロンが 200\n",
    "  - ウエイトの数は 64 x 200 = 12,800、バイアスが 200、パラメータ数の合計は 12,800 + 200 = 13,000。\n",
    "\n",
    "2 つ目の Dense\n",
    "  - 入力が 200\n",
    "  - ニューロンが 5\n",
    "  - ウエイトの数は 200 x 5 = 1,000、バイアスが 5、パラメータ数の合計は 1,000 + 5 = 1,005。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1 (Dense)                 (None, 200)          13000       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_1 (Dropout)             (None, 200)          0           Dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "exists (Dense)                  (None, 1)            201         Dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Dense)                    (None, 4)            804         Dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,005\n",
      "Trainable params: 14,005\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model.\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "inputs = Input(shape=(X.shape[-1], ), name='Input')\n",
    "x = Dense(200, activation='relu', name='Dense_1')(inputs)\n",
    "x = Dropout(0.2, name='Dropout_1')(x)\n",
    "exists = Dense(1, activation='sigmoid', name='exists')(x)\n",
    "bbox = Dense(4, activation='linear', name='bbox')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[exists, bbox])\n",
    "model.compile(\n",
    "    'adadelta', \n",
    "    loss={'exists': exists_loss, 'bbox': bboxes_loss})\n",
    "    # loss={'exists': 'binary_crossentropy', 'bbox': 'mean_absolute_error'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.4547 - exists_loss: 0.0814 - bbox_loss: 0.3734 - val_loss: 0.1381 - val_exists_loss: 0.0082 - val_bbox_loss: 0.1298\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.1791 - exists_loss: 0.0047 - bbox_loss: 0.1745 - val_loss: 0.0821 - val_exists_loss: 0.0022 - val_bbox_loss: 0.0798\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1488 - exists_loss: 0.0019 - bbox_loss: 0.1469 - val_loss: 0.0670 - val_exists_loss: 0.0012 - val_bbox_loss: 0.0659\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.1375 - exists_loss: 0.0012 - bbox_loss: 0.1363 - val_loss: 0.0591 - val_exists_loss: 7.8472e-04 - val_bbox_loss: 0.0583\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.1306 - exists_loss: 8.9072e-04 - bbox_loss: 0.1297 - val_loss: 0.0516 - val_exists_loss: 6.3841e-04 - val_bbox_loss: 0.0509\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.1267 - exists_loss: 7.6058e-04 - bbox_loss: 0.1260 - val_loss: 0.0494 - val_exists_loss: 5.4504e-04 - val_bbox_loss: 0.0489\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.1233 - exists_loss: 6.7750e-04 - bbox_loss: 0.1226 - val_loss: 0.0476 - val_exists_loss: 4.9595e-04 - val_bbox_loss: 0.0471\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.1206 - exists_loss: 6.4549e-04 - bbox_loss: 0.1200 - val_loss: 0.0445 - val_exists_loss: 4.4530e-04 - val_bbox_loss: 0.0441\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.1182 - exists_loss: 5.8924e-04 - bbox_loss: 0.1176 - val_loss: 0.0500 - val_exists_loss: 4.3723e-04 - val_bbox_loss: 0.0495\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.1171 - exists_loss: 5.7103e-04 - bbox_loss: 0.1166 - val_loss: 0.0495 - val_exists_loss: 3.9726e-04 - val_bbox_loss: 0.0491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1615b6b7da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train.\n",
    "model.fit(\n",
    "    train_X, [train_y_exists, train_y_bboxes], epochs=10,\n",
    "    validation_data=(test_X, [test_y_exists, test_y_bboxes]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict bounding boxes existance and the location on the test images.\n",
    "pred_exists, pred_bboxes = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(exists1, exists2, bbox1, bbox2):\n",
    "    '''\n",
    "    Calculate overlap between two bounding boxes [x, y, w, h]\n",
    "    as the area of intersection over the area of unity\n",
    "    '''\n",
    "    if 0.5 <= exists1 and 0.5 <= exists2:\n",
    "        x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "        x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "        w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "        h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "        if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "            return 0.\n",
    "        I = w_I * h_I\n",
    "        U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "        return I / U\n",
    "    else:\n",
    "        if exists1 < 0.5 and exists2 < 0.5:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Show a few images and predicted bounding boxes from the test dataset. \n",
    "plt.figure(figsize=(12, 3))\n",
    "for i_subplot in range(1, 5):\n",
    "    plt.subplot(1, 4, i_subplot)\n",
    "    i = np.random.randint(len(test_imgs))\n",
    "    plt.imshow(\n",
    "        test_imgs[i].T, cmap='Greys', interpolation='none',\n",
    "        origin='lower', extent=[0, img_size, 0, img_size])\n",
    "    pred_bbox, test_bbox, pred_exist, test_exist = \\\n",
    "            pred_bboxes[i], test_y_bboxes[i], pred_exists[i], test_y_exists[i]\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle(\n",
    "        (pred_bbox[0], pred_bbox[1]),\n",
    "        pred_bbox[2], pred_bbox[3], ec='r', fc='none'))\n",
    "    iou = IOU(pred_exist, test_exist, pred_bbox, test_bbox)\n",
    "    plt.annotate(\n",
    "        'IOU: {:.2f}'.format(iou),\n",
    "        (max(0.0, pred_bbox[0]), pred_bbox[1]+pred_bbox[3]+0.2), color='r')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('plots/bw-single-rectangle_prediction.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IOU: 0.876\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean IOU (overlap) between the predicted and expected\n",
    "# bounding boxes on the test dataset. \n",
    "summed_IOU = 0.\n",
    "for pred_bbox, test_bbox, pred_exist, test_exist in \\\n",
    "        zip(pred_bboxes, test_y_bboxes, pred_exists, test_y_exists):\n",
    "    summed_IOU += IOU(pred_exist, test_exist, pred_bbox, test_bbox)\n",
    "mean_IOU = summed_IOU / len(pred_bboxes)\n",
    "print(\"Mean IOU: {0:.3f}\".format(mean_IOU))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
