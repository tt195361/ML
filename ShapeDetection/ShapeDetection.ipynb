{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShapeDetection\n",
    "\n",
    "Based on __[jrieke / shape-detection](https://github.com/jrieke/shape-detection/blob/master/single-rectangle.ipynb)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_size = 8\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "\n",
    "def make_image(img):\n",
    "    if np.random.rand(1) <= 0.2:\n",
    "        exists = 0.0\n",
    "        bbox = [0.0, 0.0, 0.0, 0.0]\n",
    "    else:\n",
    "        exists = 1.0\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "        x = np.random.randint(0, img_size - w)\n",
    "        y = np.random.randint(0, img_size - h)\n",
    "        img[x:x+w, y:y+h] = 1.  # set rectangle to 1\n",
    "        bbox = [x, y, w, h]\n",
    "    return (exists, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images with random rectangles and bounding boxes. \n",
    "num_imgs = 50000\n",
    "\n",
    "imgs = np.zeros((num_imgs, img_size, img_size))  # set background to 0\n",
    "exists = np.zeros((num_imgs, 1))\n",
    "bboxes = np.zeros((num_imgs, 4))   # x, y, w, h\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    exists[i_img], bboxes[i_img] = make_image(imgs[i_img])\n",
    "    \n",
    "# print(imgs[0])\n",
    "# print(exists[0])\n",
    "# print(bboxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to match the input shape of the neural network.\n",
    "X = imgs.reshape(num_imgs, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data):\n",
    "    i = int(0.8 * num_imgs)\n",
    "    train_data = data[ :i ]\n",
    "    test_data = data[ i: ]\n",
    "    return (train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test.\n",
    "train_X, test_X = split_train_test(X)\n",
    "train_y_exists, test_y_exists = split_train_test(exists)\n",
    "train_y_bboxes, test_y_bboxes = split_train_test(bboxes)\n",
    "train_imgs, test_imgs = split_train_test(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import binary_crossentropy, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "y_loss_true_exists = None\n",
    "    \n",
    "def exists_loss(y_true, y_pred):\n",
    "    global y_loss_true_exists\n",
    "    y_loss_true_exists = y_true[ : , 0]\n",
    "    return binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "def bboxes_loss(y_true, y_pred):\n",
    "    global y_loss_true_exists\n",
    "    return y_loss_true_exists * mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import binary_accuracy\n",
    "\n",
    "y_acc_true_exists = None\n",
    "y_acc_pred_exists = None\n",
    "\n",
    "def exists_acc(y_true, y_pred):\n",
    "    global y_acc_true_exists, y_acc_pred_exists\n",
    "    y_acc_true_exists = y_true[ : , 0]\n",
    "    y_acc_pred_exists = y_pred[ : , 0]\n",
    "    return binary_accuracy(y_true, y_pred)\n",
    "\n",
    "def bboxes_acc_iou(y_true, y_pred):\n",
    "    x1, y1, w1, h1 = y_true[ : , 0], y_true[ : , 1], y_true[ : , 2], y_true[ : , 3] \n",
    "    x2, y2, w2, h2 = y_pred[ : , 0], y_pred[ : , 1], y_pred[ : , 2], y_pred[ : , 3]\n",
    "    zeros = tf.zeros_like(x1)\n",
    "    \n",
    "    w_I =  tf.maximum(zeros, tf.minimum(x1 + w1, x2 + w2) - tf.maximum(x1, x2))\n",
    "    h_I =  tf.maximum(zeros, tf.minimum(y1 + h1, y2 + h2) - tf.maximum(y1, y2))\n",
    "\n",
    "    I = w_I * h_I\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "    return I / U\n",
    "\n",
    "def bboxes_acc(y_true, y_pred):\n",
    "    global y_acc_true_exists, y_acc_pred_exists\n",
    "\n",
    "    zeros = tf.zeros_like(y_acc_true_exists)\n",
    "    ones = tf.ones_like(y_acc_true_exists)\n",
    "\n",
    "    both_not_exists = tf.logical_and(\n",
    "        tf.less(y_acc_true_exists, 0.5), tf.less(y_acc_pred_exists, 0.5))\n",
    "    acc_1 = tf.where(both_not_exists, ones, zeros)\n",
    "\n",
    "    both_exists = tf.logical_and(\n",
    "        tf.greater_equal(y_acc_true_exists, 0.5), tf.greater_equal(y_acc_pred_exists, 0.5))\n",
    "    acc_2 = tf.where(both_exists, bboxes_acc_iou(y_true, y_pred), acc_1)\n",
    "    \n",
    "    return acc_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 つ目の Dense\n",
    "  - 入力が 64\n",
    "  - ニューロンが 200\n",
    "  - ウエイトの数は 64 x 200 = 12,800、バイアスが 200、パラメータ数の合計は 12,800 + 200 = 13,000。\n",
    "\n",
    "2 つ目の Dense\n",
    "  - 入力が 200\n",
    "  - ニューロンが 5\n",
    "  - ウエイトの数は 200 x 5 = 1,000、バイアスが 5、パラメータ数の合計は 1,000 + 5 = 1,005。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1012 13:47:40.915672  8104 deprecation_wrapper.py:119] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1012 13:47:40.958557  8104 deprecation_wrapper.py:119] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1012 13:47:41.006440  8104 deprecation_wrapper.py:119] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1012 13:47:41.008425  8104 deprecation_wrapper.py:119] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1012 13:47:41.026376  8104 deprecation.py:506] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1012 13:47:41.119127  8104 deprecation_wrapper.py:119] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1012 13:47:41.167001  8104 deprecation_wrapper.py:119] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1012 13:47:41.178968  8104 deprecation.py:323] From C:\\Users\\tsuda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1 (Dense)                 (None, 200)          13000       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_1 (Dropout)             (None, 200)          0           Dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "exists (Dense)                  (None, 1)            201         Dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Dense)                    (None, 4)            804         Dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,005\n",
      "Trainable params: 14,005\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model.\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "inputs = Input(shape=(X.shape[-1], ), name='Input')\n",
    "x = Dense(200, activation='relu', name='Dense_1')(inputs)\n",
    "x = Dropout(0.2, name='Dropout_1')(x)\n",
    "exists = Dense(1, activation='sigmoid', name='exists')(x)\n",
    "bbox = Dense(4, activation='linear', name='bbox')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[exists, bbox])\n",
    "model.compile(\n",
    "    'adadelta', \n",
    "    loss={'exists': exists_loss, 'bbox': bboxes_loss},\n",
    "    metrics={'exists': exists_acc, 'bbox': bboxes_acc})\n",
    "    # loss={'exists': 'binary_crossentropy', 'bbox': 'mean_absolute_error'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.4422 - exists_loss: 0.0758 - bbox_loss: 0.3664 - exists_exists_acc: 0.9781 - bbox_bboxes_acc: 0.4943 - val_loss: 0.1299 - val_exists_loss: 0.0074 - val_bbox_loss: 0.1226 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.7353\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1742 - exists_loss: 0.0043 - bbox_loss: 0.1698 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.6511 - val_loss: 0.0844 - val_exists_loss: 0.0020 - val_bbox_loss: 0.0824 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.7805\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.1456 - exists_loss: 0.0018 - bbox_loss: 0.1439 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.6822 - val_loss: 0.0670 - val_exists_loss: 0.0011 - val_bbox_loss: 0.0659 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8327\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.1351 - exists_loss: 0.0011 - bbox_loss: 0.1340 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.6961 - val_loss: 0.0561 - val_exists_loss: 7.5414e-04 - val_bbox_loss: 0.0554 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8400\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.1285 - exists_loss: 8.6768e-04 - bbox_loss: 0.1277 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.7063 - val_loss: 0.0503 - val_exists_loss: 6.0963e-04 - val_bbox_loss: 0.0497 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8559\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.1247 - exists_loss: 7.5899e-04 - bbox_loss: 0.1239 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.7125 - val_loss: 0.0462 - val_exists_loss: 5.2756e-04 - val_bbox_loss: 0.0457 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8720\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.1216 - exists_loss: 7.0288e-04 - bbox_loss: 0.1209 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.7182 - val_loss: 0.0498 - val_exists_loss: 4.6046e-04 - val_bbox_loss: 0.0494 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8557\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.1188 - exists_loss: 6.2528e-04 - bbox_loss: 0.1182 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.7226 - val_loss: 0.0453 - val_exists_loss: 4.1255e-04 - val_bbox_loss: 0.0449 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8672\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.1172 - exists_loss: 5.7136e-04 - bbox_loss: 0.1166 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.7258 - val_loss: 0.0426 - val_exists_loss: 3.8134e-04 - val_bbox_loss: 0.0422 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8813\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.1156 - exists_loss: 5.5620e-04 - bbox_loss: 0.1151 - exists_exists_acc: 1.0000 - bbox_bboxes_acc: 0.7294 - val_loss: 0.0444 - val_exists_loss: 3.6136e-04 - val_bbox_loss: 0.0441 - val_exists_exists_acc: 1.0000 - val_bbox_bboxes_acc: 0.8819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1884a227ac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train.\n",
    "model.fit(\n",
    "    train_X, [train_y_exists, train_y_bboxes], epochs=10,\n",
    "    validation_data=(test_X, [test_y_exists, test_y_bboxes]), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict bounding boxes existance and the location on the test images.\n",
    "pred_exists, pred_bboxes = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(exists1, exists2, bbox1, bbox2):\n",
    "    '''\n",
    "    Calculate overlap between two bounding boxes [x, y, w, h]\n",
    "    as the area of intersection over the area of unity\n",
    "    '''\n",
    "    if 0.5 <= exists1 and 0.5 <= exists2:\n",
    "        x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "        x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "        w_I = max(0.0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "        h_I = max(0.0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "\n",
    "        I = w_I * h_I\n",
    "        U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "        return I / U\n",
    "    else:\n",
    "        if exists1 < 0.5 and exists2 < 0.5:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Show a few images and predicted bounding boxes from the test dataset. \n",
    "plt.figure(figsize=(12, 3))\n",
    "for i_subplot in range(1, 5):\n",
    "    plt.subplot(1, 4, i_subplot)\n",
    "    i = np.random.randint(len(test_imgs))\n",
    "    plt.imshow(\n",
    "        test_imgs[i].T, cmap='Greys', interpolation='none',\n",
    "        origin='lower', extent=[0, img_size, 0, img_size])\n",
    "    pred_bbox, test_bbox, pred_exist, test_exist = \\\n",
    "            pred_bboxes[i], test_y_bboxes[i], pred_exists[i], test_y_exists[i]\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle(\n",
    "        (pred_bbox[0], pred_bbox[1]),\n",
    "        pred_bbox[2], pred_bbox[3], ec='r', fc='none'))\n",
    "    iou = IOU(pred_exist, test_exist, pred_bbox, test_bbox)\n",
    "    plt.annotate(\n",
    "        'IOU: {:.2f}'.format(iou),\n",
    "        (max(0.0, pred_bbox[0]), pred_bbox[1]+pred_bbox[3]+0.2), color='r')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('plots/bw-single-rectangle_prediction.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IOU: 0.882\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean IOU (overlap) between the predicted and expected\n",
    "# bounding boxes on the test dataset. \n",
    "summed_IOU = 0.\n",
    "for pred_bbox, test_bbox, pred_exist, test_exist in \\\n",
    "        zip(pred_bboxes, test_y_bboxes, pred_exists, test_y_exists):\n",
    "    summed_IOU += IOU(pred_exist, test_exist, pred_bbox, test_bbox)\n",
    "mean_IOU = summed_IOU / len(pred_bboxes)\n",
    "print(\"Mean IOU: {0:.3f}\".format(mean_IOU))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
